#' helper function to generate confounds txt file for inclusion as additional regressors
#'
#' @details This function checks for whether an l1 confounds file already exists in the expected location.
#'   If it does not, the l1 confounds file will be generated according to the $confound_settings$l1_confound_regressors
#'   variable. If that is NULL, no confounds will be created.
#'
#' Confounds are generated by looking for motion parameters based on $confound_settings$motion_params_file and
#'   $confound_settings$confound_input_file. These are integrated, then columns that are requested in
#'   $confound_settings$l1_confound_regressors are written to a text file in the analysis subfolder for each subject
#'
#' Likewise, any run-level exclusions are tested according to $confound_settings$exclude_run. This should be a
#'   quoted expression that can tested against the confounds data.frame such that a single TRUE/FALSE is returned
#'   indicating whether a run is excluded (TRUE) or retained (FALSE) for higher-level analyses.
#'
#' @return a list containing: confounds=<location of l1 confounds file>, exclude_run=<TRUE/FALSE denoting run exclusion,
#'   exclude_data=<location of file containing columns used to calculate run exclusion>
#' @param id The subject id
#' @param session The session number
#' @param run_number The run number
#' @param gpa a \code{glm_pipeline_arguments} object containing pipeline specification
get_l1_confounds <- function(id = NULL, session = NULL, run_number = NULL, gpa, drop_volumes=0L, last_volume=NULL, demean=TRUE) {
  if (checkmate::test_null(id)) { stop("get_l1_confounds requires a specific id for lookup") }
  checkmate::assert_integerish(session, null.ok=TRUE)
  if (is.null(session)) session <- 1
  checkmate::assert_integerish(run_number, lower=1, null.ok = FALSE)
  checkmate::assert_class(gpa, "glm_pipeline_arguments")
  checkmate::assert_integerish(drop_volumes, lower = 0)
  checkmate::assert_integerish(last_volume, null.ok = TRUE)

  lg <- lgr::get_logger("glm_pipeline/l1_setup")

  # structure to return if this lookup fails (predictable elements so that caller can handle them)
  empty_set <- list(
    l1_confound_file = NA_character_, l1_confounds_df = data.frame(),
    exclude_run = FALSE, exclude_data = data.frame()
  )

  # lookup run information
  rinfo <- gpa$run_data %>% dplyr::filter(id == !!id & session == !!session & run_number == !!run_number)
  if (nrow(rinfo) > 1L) {
    print(rinfo)
    lg$error("Multiple matches for a single run in get_l1_confounds.")
    return(empty_set)
  } else if (nrow(rinfo) == 0L) {
    lg$error("Unable to locate a record in gpa$run_data for id %s, session %s, run_number %s.", id, session, run_number)
    return(empty_set)
  }

  # Park confound files in an analysis-level subfolder, not a particular model, since they are re-used across models.
  # Note: normalizePath will fail to evaluate properly if directory does not exist
  analysis_outdir <- get_output_directory(id=id, session=session, gpa=gpa, create_if_missing = TRUE, what="sub")

  # Determine whether we should be returning information about l1 confound regressors
  # and whether this information has already been calculated
  generate_l1_confounds <- FALSE
  if (is.null(gpa$confound_settings$l1_confound_regressors)) {
    # no confounds requested
    expected_l1_confound_file <- NA_character_
  } else {
    expected_l1_confound_file <- file.path(analysis_outdir, paste0("run", run_number, "_l1_confounds.txt"))
    if (!file.exists(expected_l1_confound_file)) {
      lg$debug("Expected confounds file does not exist: %s.", expected_l1_confound_file)
      generate_l1_confounds <- TRUE
    }
  }

  # determine whether we should be returning information about run exclusions
  # and whether this information has already been calculated
  generate_run_exclusion <- FALSE
  if (is.null(gpa$confound_settings$exclude_run)) {
    # no basis for exclusion (all runs okay)
    exclude_run <- FALSE
  } else {
    exclude_df <- read_df_sqlite(gpa = gpa, id = id, session = session, run_number = run_number, table = "l1_run_exclusions")
    exclude_data <- read_df_sqlite(gpa = gpa, id = id, session = session, run_number = run_number, table = "l1_exclusion_data")
    if (!is.null(exclude_df)) {
      exclude_run <- as.logical(exclude_df$exclude_run)
    } else {
      lg$debug("No record of run exclusion exists in database: %s.", gpa$output_locations$sqlite_db)
      exclude_run <- NA #default to missing
      generate_run_exclusion <- TRUE
    }
  }

  # If both run exclusion and l1 confounds exist, just use the precalculated information
  if (!(generate_l1_confounds || generate_run_exclusion)) {
    if (!is.na(expected_l1_confound_file)) lg$debug("Returning extant file: %s in get_l1_confounds", expected_l1_confound_file)

    return(list(
      l1_confound_file = expected_l1_confound_file, 
      l1_confounds_df = data.table::fread(expected_l1_confound_file, data.table = FALSE),
      exclude_run = exclude_run, exclude_data = exclude_data
    ))
  }

  # read external confounds file
  confound_df <- read_df_sqlite(gpa = gpa, id = id, session = session, run_number = run_number, table = "l1_confound_inputs")
  if (is.null(confound_df) && isTRUE(rinfo$confound_input_file_present[1])) {
    lg$debug("Generating l1 confounds for id: %s, session: %s, run_number: %s", id, session, run_number)
    cfile <- get_mr_abspath(rinfo, "confound_input_file")[1]
    lg$debug("Reading confound file: %s", cfile)
    confound_df <- tryCatch(data.table::fread(cfile, data.table=FALSE, na.strings=gpa$confound_settings$na_strings), 
    error = function(e) {
      lg$error("Failed to read confound file: %s with error %s", cfile, as.character(e))
      return(NULL)
    })

    if (!is.null(gpa$confound_settings$confound_input_colnames) && !is.null(confound_df)) {
      if (length(gpa$confound_settings$confound_input_colnames) != ncol(confound_df)) {
        lg$warn(
          "Mismatch in number of columns in confound file: %s relative to $confound_settings$confound_input_colnames",
          rinfo$confound_input_file[1]
        )
      } else {
        # only set names in confound_df if the number of columns matches
        data.table::setnames(confound_df, gpa$confound_settings$confound_input_colnames)
      }
    }

    if (is.null(last_volume)) {
      last_volume <- nrow(confound_df)
      lg$debug("Assuming that last row of confounds file is final volume: %d", last_volume)
    }
    confound_df <- confound_df[(1 + drop_volumes):last_volume, ]

    # cache original confounds to db
    insert_df_sqlite(gpa, id = id, session = session, run_number = run_number, data = confound_df, table = "l1_confound_inputs")
  }

  #read motion parameters file
  motion_df <- read_df_sqlite(gpa = gpa, id = id, session = session, run_number = run_number, table = "l1_motion_parameters")
  if (is.null(motion_df) && isTRUE(rinfo$motion_params_present[1])) {
    lg$debug("Generating motion params for id: %s, session: %s, run_number: %s", id, session, run_number)
    mfile <- get_mr_abspath(rinfo, "motion_params_file")[1]
    lg$debug("Reading motion file: %s", mfile)

    # Note: Avoid demeaning columns within generate_motion_regressors so that calculated regressors do not
    # change scale prior to testing the run exclusion criteria below. Demeaning can be applied safely thereafter.
    motion_df <- tryCatch({
      generate_motion_regressors(
        mfile,
        col.names = gpa$confound_settings$motion_params_colnames,
        regressors = gpa$confound_settings$all_confound_columns,
        drop_volumes = drop_volumes, last_volume = last_volume, demean=FALSE,
        na.strings=gpa$confound_settings$na_strings
      )}, error = function(e) {
      lg$error("Failed to read motion file: %s with error %s", rinfo$motion_params_file[1], as.character(e))
      return(NULL)
    })

    # cache motion parameters to db
    insert_df_sqlite(gpa, id=id, session=session, run_number=run_number, data=motion_df, table="l1_motion_parameters")
  }

  # combine motion and confound files
  if (is.null(motion_df) && is.null(confound_df)) {
    lg$info("Neither confounds nor motion parameters are available for %s", rinfo$run_nifti[1L])
    return(empty_set)
  } else if (is.null(motion_df)) {
    all_confounds <- confound_df
  } else if (is.null(confound_df)) {
    all_confounds <- motion_df
  } else {
    if (nrow(motion_df) != nrow(confound_df)) {
      lg$error("Number of rows in motion_df is: %d and in confound_df is %d. Cannot combine", nrow(motion_df), nrow(confound_df))
      return(empty_set)
    } else {
      # prefer confound_df as authoritative in cases where motion_df has overlapping columns
      overlap_names <- intersect(names(motion_df), names(confound_df))
      if (length(overlap_names) > 0L) {
        lg$info(
          "Motion parameters have overlapping columns with confounds file: %s. Preferring confounds to motion params",
          rinfo$confound_input_file[1L]
        )
        lg$info("Overlap: %s", overlap_names)
        data.table::setnames(motion_df, old = overlap_names, new = paste0(overlap_names, ".mot"))
      }

      all_confounds <- dplyr::bind_cols(confound_df, motion_df)
    }
  }

  # handle NA values in confounds -> convert to 0
  has_na <- sapply(all_confounds, anyNA)
  if (any(has_na)) {
    lg$warn("NA values found in confounds file: %s", cfile)
    lg$warn("These will be converted to 0s before evaluating exclude_run and writing l1_confound_file: %s", expected_l1_confound_file)
    all_confounds[, has_na] <- as.data.frame(apply(all_confounds[, has_na], 2, function(x) {
      x[is.na(x)] <- 0
      return(x)
    }))
  }

  # calculate whether to retain or exclude this run
  if (isTRUE(generate_run_exclusion) && !is.null(gpa$confound_settings$exclude_run)) {
    if (!all(gpa$confound_settings$run_exclusion_columns %in% names(all_confounds))) {
      lg$warn("Missing exclusion columns for subject: %s, session: %s", rinfo$id[1L], rinfo$session[1L])
      lg$warn("Column: %s", setdiff(gpa$confound_settings$run_exclusion_columns, names(all_confounds)))
      lg$warn("We will exclude this run from analysis until this is resolved!")
      exclude_run <- TRUE
    } else {
      # evaluate run exclusion expression
      exclude_run <- tryCatch(with(all_confounds, eval(parse(text = gpa$confound_settings$exclude_run))),
        error = function(e) {
          lg$error(
            "Problem evaluating run exclusion for subject: %s, session: %s, run_number: %s, expr: %s",
            id, session, run_number,
            gpa$confound_settings$exclude_run
          )
          lg$error("Defaulting to exclusion of run.")
          return(TRUE)
        }
      )

      if (length(exclude_run) > 1L) {
        lg$error("Run exclusion expression %s returned %d results!", gpa$confound_settings$exclude_run, length(exclude_run))
        lg$error("Modify the expression so that it returns a single TRUE/FALSE.")
        lg$error("Defaulting to exclusion of run.")
        exclude_run <- TRUE
      }
    }

    # write the exclusion basis to the database
    exclude_data <- all_confounds[, intersect(gpa$confound_settings$run_exclusion_columns, names(all_confounds)), drop = FALSE]
    insert_df_sqlite(gpa, id = id, session = session, run_number = run_number, data = exclude_data, table = "l1_exclusion_data")
    insert_df_sqlite(gpa,
      id = id, session = session, run_number = run_number,
      data = data.frame(exclude_run = exclude_run), table = "l1_run_exclusions"
    )
  }

  # check for missing confound columns
  if (!all(gpa$confound_settings$l1_confound_regressors %in% names(all_confounds))) {
    lg$warn("Missing confound columns for subject: %s, session: %s", rinfo$id[1L], rinfo$session[1L])
    lg$warn("Column: %s", setdiff(gpa$confound_settings$l1_confound_regressors, names(all_confounds)))
  }

  # trim l1 confounds to only those requested
  all_confounds <- all_confounds[, intersect(gpa$confound_settings$l1_confound_regressors, names(all_confounds))]
  num_cols <- sapply(all_confounds, class) %in% c("integer", "numeric")
  if (any(!num_cols)) {
    lg$warn("Confound file contains non-numeric columns. Not sure what will happen!")
    lg$warn("Column: %s", names(all_confounds)[!num_cols])
  }

  # demean confound regressors, if requested (usually a good idea)
  if (isTRUE(demean)) {
    lg$debug("Demeaning columns of l1 confounds matrix: %s", expected_l1_confound_file)

    all_confounds[, num_cols] <- as.data.frame(apply(all_confounds[, num_cols], 2, function(x) {
      x - mean(x, na.rm = TRUE)
    }))
  }

  # incorporate spike regressors if requested (not used in conventional AROMA)
  spikes <- compute_spike_regressors(motion_df, spike_volumes, lg = lg)
  if (!is.null(spikes)) all_confounds <- cbind(all_confounds, spikes)

  lg$debug("Writing l1 confounds to file: %s", expected_l1_confound_file)
  write.table(all_confounds, file = expected_l1_confound_file, row.names = FALSE, col.names = FALSE)

  # cache final confounds to db
  insert_df_sqlite(gpa, id = id, session = session, run_number = run_number, data = all_confounds, table = "l1_confounds")

  return(list(
    l1_confound_file = expected_l1_confound_file,
    l1_confounds_df = all_confounds,
    exclude_run = exclude_run, exclude_data = exclude_data
  ))
}

# fit behavioral data for all participants who completed emo clock in scanner
# setup model-based fMRI GLM analysis for based on fitted data

model_clock_fmri_lvl1 <- function(trial_statistics, id_col=NULL, subject_data=NULL, drop_volumes=6, ncpus=1,
                                  expectdir="mni_5mm_aroma", expectfile = "nfaswuktm_clock[0-9]_5.nii.gz",
                                  sceptic_run_signals=c("v_chosen", "v_entropy", "d_auc", "pe_max"), #which signals to model jointly in LVL1
                                  l1_contrasts=NULL,
                                  outdir=NULL, glm_software="fsl", ...) {

  stopifnot(is.numeric(ncpus) && ncpus >= 1)
  if (is.null(id_col)) { stop("Need to specify an id column in subject_data") }
  if (is.null(subject_data)) { stop("Need to specify a subject_data data.frame") }
  
  require(foreach) #contains registerDoSEQ
  
  #setup parallel worker pool, if requested
  if (ncpus > 1) {
    require(doParallel)
    cl <- makePSOCKcluster(ncpus)
    registerDoParallel(cl)
    
    on.exit(try(stopCluster(cl))) #cleanup pool upon exit of this function
  } else {
    registerDoSEQ() #formally register a sequential 'pool' so that dopar is okay
  }

  #trial_statistics is the full data.frame generated by compile_trial_level_dataframes.R, which contains trial-level information for all subjects.
  #split on id to iterate over subjects
  by_subj <- split(trial_statistics, trial_statistics[[id_col]])

  # loop over each subject, identify relevant fMRI data, and setup FSL level 1 files
  #by_subj <- by_subj[4]
  ll <- foreach(b = iter(by_subj), .inorder=FALSE, .packages=c("dependlab"),
    .export=c("truncateRuns", "fsl_sceptic_model", "spm_sceptic_model", "runFSLCommand", "populate_sceptic_signals") ) %dopar% {

      subid <- b[[id_col]][1] #subject id
      #scandate <- sub("^.*/Basic/\\w+/(\\d+)/.*$", "\\1", b, perl=TRUE)  #not currently accessible

      mrfiles <- c() #force clear of mr files over subjects to avoid potential persistence from one subject to the next

      mrmatch <- subject_data$mr_dir[subject_data[[id_col]] == subid]

      if (length(mrmatch) != 1L) {
        warning("Unable to find fMRI directory for subid: ", subid)
        return(NULL)
      }        
      
      if (! file.exists(file.path(mrmatch, expectdir))) {
        warning("Unable to find preprocessed data ", expectdir, " for subid: ", subid)
        return(NULL)
      }
      
      ## Find processed fMRI run-level data for this subject
      ##mrfiles <- list.files(mrmatch, pattern=expectfile, full.names=TRUE, recursive=TRUE)
      ##cat(paste0("command: find ", mrmatch, " -iname '", expectfile, "' -ipath '*", expectdir, "*' -type f\n"))
      mrfiles <- system(paste0("find ", mrmatch, " -iname '", expectfile, "' -ipath '*", expectdir, "*' -type f | sort -n"), intern=TRUE)
      mrfiles <- mrfiles[!grepl("(exclude|bbr_noref|old)", mrfiles, ignore.case=TRUE)] #if exclude is in path/filename, then skip

      ##mrrunnums <- as.integer(sub(paste0(".*", expectfile, "$"), "\\1", mrfiles, perl=TRUE))
      mrrunnums <- as.integer(sub(paste0(".*clock(\\d+).*$"), "\\1", mrfiles, perl=TRUE)) #extract run number from file name

      ##NB. If we reorder the mrfiles, then the run numbers diverge unless we sort(mrrunnums). Remove for now for testing
      ##mrfiles <- mrfiles[order(mrrunnums)] #make absolutely sure that runs are ordered ascending

      if (length(mrfiles) == 0L) {
        warning("Unable to find any preprocessed MB files in dir: ", mrmatch)
        return(NULL)
      }

      ##read number of volumes from NIfTI header
      suppressMessages(library(Rniftilib))
      runlengths <- unname(sapply(mrfiles, function(x) { Rniftilib::nifti.image.read(x, read_data=0)$dim[4L] }))
      detach("package:Rniftilib", unload=TRUE) #necessary to avoid dim() conflict with oro.nifti
      
      ## create truncated run files to end analysis 12s after last ITI (or big head movement)
      ## also handle removal of N volumes from the beginning of each run due to steady state magnetization
      mrdf <- truncateRuns(b, mrfiles, mrrunnums, runlengths, drop_volumes=drop_volumes)
      mrfiles <- mrdf$mrfile_to_analyze
      runlengths <- mrdf$last_vol_analysis
      
      message("About to analyze the following files:")
      print(mrfiles)

      if ("d_auc" %in% names(b)) { b$d_auc <- -1*b$d_auc } #invert decay such that higher values indicate greater decay

      if (glm_software == "fsl") {
        #Setup FSL SCEPTIC run-level models for each combination of signals
        tryCatch(fsl_sceptic_model(b, sceptic_run_signals, l1_contrasts, mrfiles, runlengths, mrrunnums, drop_volumes=drop_volumes, outdir=outdir, ...),
          error=function(e) {
            cat("Subject: ", b[[id_col]][1], ", run variant: ", paste(sceptic_run_signals, collapse="-"), " failed with mrfiles: \n",
              paste(mrfiles, collapse="\n"), "\n", "error: ", as.character(e), "\n\n", file="lvl1_crashlog.txt", append=TRUE)
          })
      } else if (glm_software == "spm") {
        #Setup FSL SCEPTIC run-level models for each combination of signals
        tryCatch(spm_sceptic_model(b, sceptic_run_signals, mrfiles, runlengths, mrrunnums, drop_volumes=drop_volumes, outdir=outdir, ...),
          error=function(e) {
            cat("Subject: ", b[[id_col]][1], ", run variant: ", paste(sceptic_run_signals, collapse="-"), " failed with mrfiles: \n",
              paste(mrfiles, collapse="\n"), "\n", "error: ", as.character(e), "\n\n", file="lvl1_crashlog.txt", append=TRUE)
          })

      }

      message("completed processing of subject: ", subid)
      cat("\n\n\n")
    }
  
}

---
title: "Familywise error correction for voxelwise GLMs in fmri.pipeline"
author: "Michael Hallquist"
date: "24 Jan 2022"
output:
  html_document:
    code_folding: hide
    df_print: kable
    mathjax: default
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
  pdf_document:
    code_folding: hide
    df_print: kable
    number_sections: yes
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
if (!require(pacman)) { install.packages("pacman"); library(pacman) }
p_load(tidyverse, fmri.pipeline)
knitr::opts_chunk$set(echo = TRUE) #print code by default
options(digits=3)
```

This vignette provides an overview of familywise error correction for voxelwise GLM analyses in fmri.pipeline.

# AFNI 3dClustSim

As outlined in Cox et al. (2017, Brain Connectivity), the conventional Gaussian random field theory approach to cluster correction in fMRI 
analysis is anticonservative in many cases because the empirical autocorrelation function of noise in fMRI has a much longer tail than the 
Gaussian distribution would predict. This was highlighted in Woo & Wager (2014) and elaborated by Eklund (2016, to greater effect).

There are a couple of improvements proposed and tested by Cox to control the familywise error rate to (nearly) .05. The package supports both
of these methods. Let's do a quick walkthrough.

## Method 1: AFNI 3dClustSim + 3dFWHMx -ACF

The basic approach to 3dClustSim (using -fwhm or -fwhmxyz) assumes a Gaussian-distributed noise structure. As noted above, this is not
realistic in fMRI data. The first correction attempts to overcome the assumption of Gaussianity by fitting a long-tailed distribution
to the noise structure of empirical data. Specifically, one passes in the first-level GLM residuals (one volume per timepoint) as inputs to
3dFWHMx and includes the -ACF flag. This flag will estimate the autocorrelation function from the data by fitting parameters of a mono-exponential
+ Gaussian mixture that can better accommodate the long-tailed spatial autocorrelations in fMRI data.

3dFWHMx produces ACF parameters for every volume in each run's residuals file. The usual approach (per AFNI) is to take the average of these
parameters per run as the best estimate of the spatial structure of noise in that run. Then, to estimate cluster correction thresholds in
3dClustSim, one further averages these run-averaged ACF parameters across all runs to achieve an overall ACF for the entire dataset. In
Cox et al., 2017, the median ACF parameters across datasets are input to 3dClustSim -- I suppose the mean could work, too, depending on whether
there are outliers that would sway it. The estimated values of this averaged 3-parameter ACF are passed to 3dClustSim with the -acf argument.

Based on the -acf input, 3dClustSim now estimates null datasets that have the spatial distribution of noise derived from the empirical data,
which better controls for FWE relative to the standard Gaussian assumption/distribution. Cox and colleagues show that at reasonable voxelwise
thresholds (p < .005 or p < .001), the -ACF approach is close to the nominal .05 alpha level (4 - 8%) when a) the spatial smoothing kernel is > 4mm FWHM,
and b) the test/contrast comes from an event-related design with many repeats of relatively brief stimuli. The false positive rate (FPR) for
block designs and small smoothing kernels (4mm FWHM) are worse, sometimes > 15%. Also, note that a voxelwise threshold of .01 or more (e.g., .02)
is far too generous for cluster correction and should be avoided in general (see Woo and Wager for more info). The above summary is depicted in Cox
et al., 2017, Fig 1 G, H, I.

### Implementing the -ACF correction in fmri.pipeline

#### Example 1: Setting up a 3dFWHMx object yourself

If you would like to run 3dFWHMx yourself using the afni_3dfwhmx wrapper class, here is an example:

```{r fwhmx}
# example FEAT LVL1 output
path <- "/proj/mnhallqlab/studies/MMClock/MR_Proc/10637_20140304/mni_5mm_aroma/sceptic_vchosen_ventropy_dauc_pemax_vtime_preconvolve/FEAT_LVL1_run1.feat"
res4d_file <- file.path(path, "stats", "res4d.nii.gz")
fwhmx_mask_file <- file.path(path, "mask.nii.gz")

test <- afni_3dfwhmx$new(input_file = res4d_file, mask_file = fwhmx_mask_file, average = "geometric")
test$run() # will run 3dFWHMx in the local compute environment (use force = TRUE to re-run completed file)
test$is_complete() # TRUE if 3dFWHMx has already completed and has generated its output files
test$get_acf_params() # average ACF params (typically combined with other datasets, then averaged, for 3dClustSim)
test$get_fwhm_by_volume() # FWHM for each sub-brik (volume)
test$get_acf_by_radius() # FWHM for each sub-brik (volume)

# commented out to avoid deleting files of interest
#test$delete_outputs(prompt = TRUE) # delete files generated by this input -- it will ask you to confirm each
```

This shows how you can run 3dFWHMx through R and read the outputs of the ACF fitting and FWHM calculation.

#### Example 2: Running 3dFWHMx for a set of residual files

The afni_3dfwhmx class is a wrapper around 3dFWHMx. In the typical ACF approach, we pass the average ACF parameters across all
datasets to 3dClustSim -acf. That is, we must provide only one set of ACF parameter estimates to 3dClustSim -acf so that the program
can generate null datasets with this spatial autocorrelation structure. We usually use 3dClustSim to calculate an FWE correction
on a group analysis that may reflect hundreds of first-level datasets (fMRI runs). The residuals from each first-level GLM must be passed
through 3dFWHMx so that the ACF parameters can inform the overall (group) ACF estimates.

Said differently, the typical 3dClustSim -acf approach requires ACF parameter averaging at two stages. First, we take the average
ACF parameters across all volumes from the first-level residuals. This is controlled by the -geom or -arith flag of 3dFWHMx, which
specifies how volume-wise ACF estimates should be combined to yield a run-wise ACF. Then, we average the run-wise ACF parameters
to derive a sample-wise ACF average that reflects the average spatial autocorrelation across all datasets in the analysis.

To aid in the estimation of ACF parameters across many runs, we provide the afni_3dfwhmx_list class. Conceptually, this is a list
of afni_3dfwhmx objects, each of which pertains to a single run of data. The goal of the afni_3fwhmx_list class is to run 3dFWHMx
for all input datasets and to provide average values for the ACF across the datasets. This average can then be passed directly to
3dClustSim -acf.

Here's a quick example:

```{r fwhmx_list}
# get ACF parameters for 8 first-level residual files for testing
# this example is simpler than typical applications where we have many subject and many runs
path <- "/proj/mnhallqlab/studies/MMClock/MR_Proc/10637_20140304/mni_5mm_aroma/sceptic_vchosen_ventropy_dauc_pemax_vtime_preconvolve"
res4d_files <- list.files(pattern = "res4d.nii.gz", path = path, full.names = T, recursive = T)
fwhmx_mask_files <- list.files(pattern = "mask.nii.gz", path = path, full.names = T, recursive = T)

# these are the files to be passed through 3dFWHMx
print(res4d_files)

# create the list object requires you to provide input and mask files for each residuals dataset of interest.
test <- afni_3dfwhmx_list$new(input_files = res4d_files, mask_files = fwhmx_mask_files, scheduler = "slurm")

# submit 3dFWHMx jobs to cluster -- the object will divide the list into smaller jobs if needed
# if 3dFWHMx has completed for all inputs already, the $submit method will just return immediately and note
# that there is nothing to submit. If you want to force re-estimation, use $submit(force = TRUE).
test$submit()

# has 3dFWHMx completed for all datasets provided to the list?
test$is_complete()

# average a, b, c parameters across datasets -- good for input to 3dClustSim -acf
test$get_acf_average()

# average effective FWHM estimate using -ACF
test$get_effective_fwhm()

# per-dataset ACF summary if you want to see what got averaged
test$get_acf_df()
```

#### Example 3: Setup 3dClustSim + 3dFWHMx -acf approach

Although you are welcome to use the afni_3dfwhmx and afni_3dfwhmx_list directly, if your purpose is to run 3dClustSim using the ACF approach,
you can ask the pipeline to run and compile the 3dFWHMx results for all level 1 residuals in a single step.

The afni_3dclustsim object will handle the 3dFWHMx batch estimation as an initial compute job, then pass the averaged ACF parameters to 3dClustSim
as a dependent compute job (i.e., 3dFWHMx has to complete before 3dClustSim starts).

This is achieved using the `fwhmx_input_files` and `fwhmx_mask_files` arguments to `afni_3dclustsim$new()`. Here, let's pass the
same level 1 residuals and mask files as above (in the 3dFWHMx list step). Here, we ask 3dClustSim to use 8 cores for parallel estimation
and we use the MNI 2009c brain mask (at 2.3mm) as the volume over which to correct for FWE (this should match the empirical data).

```{r clustsim_acf}
clustsim_acf <- afni_3dclustsim$new(
  fwhmx_input_files = res4d_files, fwhmx_mask_files = fwhmx_mask_files,
  scheduler = "slurm",
  clustsim_mask = "/proj/mnhallqlab/lab_resources/standard/mni_icbm152_nlin_asym_09c/mni_icbm152_t1_tal_nlin_asym_09c_mask_2.3mm.nii", ncpus = 8
)

# Submit the job to the scheduler. If the 3dFWHMx calls have not been completed yet for all fwhmx_input_files, this will occur first via
# a separate job submission
clustsim_acf$submit()
```

Once the above job completes, we can look at the number of voxels needed at different combinations of voxelwise and clusterwise thresholds.
```{r}
clustsim_acf$get_clustsim_df()
```

If you were curious about a cluster correction result, you can use the `dplyr::filter` function to obtain this. For example, imagine that I want to look
at the whole-brain FWE cluster threshold for all clusters defined by NN=1 (faces touching) and a voxelwise significance level of p = .001. Here's the result.

```{r}
clustsim_acf$get_clustsim_df() %>% dplyr::filter(nn==1 & pthr==.001)
```

## Method 2: AFNI 3dClustSim with 3dttest++ permutations

The second method proposed by Cox involves generating null datasets from the empirical distribution of residuals in the group analysis. That is,
if we run our group GLM, we can compute a $Y - \hat{Y}$ value for every voxel and every subject. This results in a voxelwise map per subject
that contains the residual from the group analysis.

Rather than attempt to approximate the spatial distribution of 
